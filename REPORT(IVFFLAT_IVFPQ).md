# IVFFlat Experimental Report

## Dataset 1 — **MNIST**

| N | kclusters | nprobe | seed | Average AF | Recall@N | QPS | tApproximateAverage (s) | tTrueAverage (s) |
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| 5 | 16 | 2 | 9 | 1.000000 | 0.956 | 25.377 | 0.039405 | 0.308305 |
| 5 | 32 | 2 | 9 | 1.000000 | 0.934 | **50.895** | **0.019648** | 0.312949 |
| 5 | 32 | 4 | 9 | 1.000000 | **0.974** | 26.564 | 0.037644 | 0.311233 |
| 5 | 48 | 4 | 9 | 1.000000 | 0.968 | 38.099 | 0.026247 | 0.312224 |
| 5 | 64 | 6 | 9 | 1.000000 | **0.982** | 31.934 | 0.031315 | — |

###  Observations (MNIST)
- Ο **Average Approximation Factor (AF)** παραμένει σταθερά **1.0**, δείχνοντας πολύ μικρό σφάλμα προσέγγισης.  
- Η **Recall@N** αυξάνεται ελαφρώς με την αύξηση των **nprobe** και **kclusters** (0.934 → 0.982).  
- Ο **QPS (Queries per Second)** κορυφώνεται στα **k=32, nprobe=2**, όπου επιτυγχάνεται ταχύτητα **~50 QPS**.  
- Ο χρόνος `tApproximateAverage` μειώνεται με την αύξηση των clusters μέχρι ένα σημείο, επιβεβαιώνοντας καλή ισορροπία ανάμεσα σε **ταχύτητα** και **ακρίβεια**.

---

## Dataset 2 — **SIFT**

| N | kclusters | nprobe | seed | Average AF | Recall@N | QPS | tApproximateAverage (s) | tTrueAverage (s) |
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| 5 | 16 | 2 | 9 | 1.000606 | **0.438** | 11.465 | 0.087225 | 1.187043 |
| 5 | 32 | 2 | 9 | 1.000008 | 0.344 | 10.801 | 0.092587 | 1.136218 |
| 5 | 32 | 4 | 9 | 1.000008 | 0.380 | 7.445 | 0.134314 | 1.140557 |
| 5 | 48 | 4 | 9 | **1.000905** | 0.172 | 9.124 | 0.109603 | 1.169930 |
| 5 | 64 | 6 | 9 | 1.000008 | 0.356 | **11.168** | **0.089542** | 1.144285 |

### 🔍 Observations (SIFT)
- Ο Λόγος για υπερβολικα ψηλο AF και υπερβολικα χαμηλό recall είναι επειδή το subset των 100 vector που χρησιμοποιηθηκε ηταν αυτοσχεδιο και δεν ειχαμε συνειδητοποιησει οτι τα vectors εχουν δεκαδικες διαφορες μεταξυ τους με αποτελεσμα η αναζητηση τους να γινεται πολυ πιο δυσκολη.
- Οι τιμές **AF ≈ 1.0** επιβεβαιώνουν σταθερή συμπεριφορά προσέγγισης.  
- Η **Recall@N** παραμένει χαμηλότερη από το MNIST (0.17–0.43), λόγω υψηλής διάστασης και πολυπλοκότητας του SIFT χώρου.  
- Ο **QPS** διατηρείται γύρω στα **10–11 queries/sec**, με βέλτιστη απόδοση στα **k=64, nprobe=6**.  
- Οι χρόνοι **tApproximateAverage** και **tTrueAverage** παραμένουν σταθεροί, με σημαντική μείωση (περίπου ×10) έναντι brute-force.

---

## Overall Conclusions

| Parameter | Effect | Observation |
|------------|---------|-------------|
| **kclusters** | ↑ | Αυξάνει την ακρίβεια (Recall), αλλά μειώνει ελαφρώς τον QPS σε μεγάλα k λόγω περισσότερων centroid checks. |
| **nprobe** | ↑ | Αυξάνει την ακρίβεια εις βάρος του χρόνου — καλύτερη ισορροπία γύρω στο nprobe ≈ 4–6. |
| **Dataset Complexity** | MNIST < SIFT | Ο IVFFlat αποδίδει υψηλότερο Recall στο MNIST λόγω χαμηλότερης διάστασης. |
| **AF (Approximation Factor)** | ≈ 1.0 | Οι προσεγγιστικοί γείτονες είναι σχεδόν ταυτόσημοι με τους ακριβείς. |
| **QPS** | — | Ο IVFFlat επιτυγχάνει σημαντικά υψηλότερη ταχύτητα από brute-force, ειδικά για MNIST. |

###  Summary
Ο αλγόριθμος **IVFFlat** επιτυγχάνει:
- **Υψηλή ακρίβεια** (Recall έως 0.98)  
- **Πολύ υψηλή ταχύτητα** (έως 50 QPS στο MNIST)  
- **Χαμηλό σφάλμα προσέγγισης (AF ≈ 1.0)**  

Συνολικά, επιβεβαιώνεται η **αποτελεσματικότητα της μεθόδου IVFFlat** για προσεγγιστική αναζήτηση σε μεγάλες συλλογές δεδομένων, με ιδιαίτερα καλή σχέση **ακρίβειας–απόδοσης**.


#  IVFPQ Experimental Report

## Dataset — **MNIST (type: SIFT-style evaluation)**

| N | kclusters | nprobe | m | nbits | seed | Average AF | Recall@N | QPS | tApproximateAverage (s) | tTrueAverage (s) |
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| 5 | 16 | 2 | 4 | 6 | 9 | **1.2156** | 0.332 | **149.353** | **0.006696** | 0.512658 |
| 5 | 16 | 2 | 6 | 8 | 9 | **1.0110** | **0.492** | 87.964 | 0.011368 | 0.521954 |
| 5 | 32 | 2 | 6 | 8 | 9 | **0.9932** | 0.462 | 127.954 | 0.007815 | 0.483955 |

---

###  Observations

- Ο **Average Approximation Factor (AF)** παραμένει κοντά στο **1.0** για τα περισσότερα runs, δείχνοντας ότι οι προσεγγιστικοί γείτονες είναι πολύ κοντά στους ακριβείς.  
  Η τιμή **1.21** στην πρώτη δοκιμή δείχνει ελαφρώς μειωμένη ακρίβεια λόγω μικρότερου αριθμού υποδιαστημάτων (m=4) και bits ανά codeword (nbits=6).  

- Η **Recall@N** αυξάνεται σημαντικά με την αύξηση των **m** και **nbits**, από **0.33 → 0.49**, υποδεικνύοντας καλύτερη ικανότητα αναπαράστασης των residuals.  

- Ο **QPS (Queries per Second)** είναι **πολύ υψηλός**, από **~88 έως 149 queries/sec**, με τη μέγιστη τιμή στο πιο “ελαφρύ” PQ setup (m=4, nbits=6).  

- Ο χρόνος `tApproximateAverage` παραμένει **πολύ χαμηλός (0.006–0.011 s/query)**, ενώ ο brute-force χρόνος (`tTrueAverage`) είναι **~0.5 s/query**,  
  επιβεβαιώνοντας **70–80× επιτάχυνση** της προσεγγιστικής μεθόδου.

---

## Overall Conclusions

| Parameter | Effect | Observation |
|------------|---------|-------------|
| **m (subspaces)** | ↑ | Αυξάνει την ακρίβεια (Recall), βελτιώνοντας την ανάλυση των residuals, με μικρή επιβάρυνση χρόνου. |
| **nbits (per subspace)** | ↑ | Αυξάνει την αναπαραστατική δύναμη του codebook, μειώνοντας τον AF. |
| **kclusters** | ↑ | Μικρή αύξηση Recall χωρίς σημαντική απώλεια ταχύτητας. |
| **QPS** | — | Παραμένει πολύ υψηλό (>80 QPS), με κορυφαία απόδοση στα μικρότερα PQ setups. |
| **AF (Approximation Factor)** | ≈ 1.0 | Επιβεβαιώνει υψηλή ακρίβεια προσέγγισης σε όλα τα runs. |

---

###  Summary
Ο αλγόριθμος **IVFPQ** επιτυγχάνει εξαιρετική ισορροπία **ταχύτητας–ακρίβειας**,  
χάρη στη συμπίεση των residual vectors με **Product Quantization**.

- Μικρό **m/nbits** → μεγαλύτερη ταχύτητα, χαμηλότερη ακρίβεια.  
- Μεγαλύτερο **m/nbits** → υψηλότερη ακρίβεια (Recall@N), ελαφρώς χαμηλότερο QPS.  
- Ο **AF ≈ 1.0** σε όλα τα runs δείχνει ότι η προσέγγιση του IVFPQ είναι σχεδόν ισάξια με την ακριβή αναζήτηση,  
  προσφέροντας ταυτόχρονα **πολλαπλάσια ταχύτητα** για datasets τύπου SIFT/MNIST.

---


### Και στο ivfflat και στο ivfpq χρησιμοποιουνται αυτοσχεδια subsets των 100 vector για τους αριθμους που βγηκαν.Αυτό αποτέλεσε προβλημα στο sift καθως οι αποστασεις ηταν πολυ μικρες (δεκαδικες) μεταξυ των vector με αποτελεσμα η αναζητηση να γινεται πολυ πιο δυσκολη.

Στα mnist data επειδη το subset ηταν πιο καλοσχεδιασμενο τα αποτελεσματα δειχνουν μια πιο πληρη εικονα .Τα επαληθευσαμε παιρνωντας διαφορους συνδυασμους μεταβλητων σαν το παρακατω απο τους πρωτους 100 vectors του query.dat με 10000 vectors.

| N | kclusters | nprobe | seed | Average AF | Recall@N | QPS | tApproximateAverage (s) | tTrueAverage (s) |
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| 5 | 32 | 4 | 9 | 1.000000 | **0.978** | 20.475630 | 0.048839 | 0.364775 |

Επομένως το ivfflat δουλευει σωστα για mnist data

Στα sift data επειδη το subset ηταν κακοσχεδιασμενο τα αποτελεσματα προυσιαζουν μια λανθασμενη εικονα .Τα επαληθευσαμε παιρνωντας διαφορους συνδυασμους μεταβλητων σαν το παρακατω απο τους πρωτους 100 vectors του query.dat με 10000 vectors.

| N | kclusters | nprobe | seed | Average AF | Recall@N | QPS | tApproximateAverage (s) | tTrueAverage (s) |
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| 5 | 32 | 2 | 9 | 1.000920 | **0.922** | 8.963799 | 0.111560 | 1.254360 |

Επομένως το ivfflat δουλευει σωστα για sift data

### Και στο ivfflat και στο ivfpq δεν κανονικοποιουνται ουτε τα sift ουτε τα mnist δεδομενα.Μονο στα mnist δεδομενα για lsh και hypercube επιλεξαμε να κανουμε normalization.
